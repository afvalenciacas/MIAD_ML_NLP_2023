{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Tokenización de textos  \n",
    "\n",
    "En este taller podrán poner en práctica sus conocimientos sobre preprocesamiento de texto (tokenización). El taller está constituido por 5 puntos, en los cuales deberan seguir las intrucciones de cada numeral para su desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos detección de toxicidad en comentarios\n",
    "\n",
    "En este taller se usará el conjunto de datos de detección de toxicidad en comentarios de la base de datos de Kaggle. Cada observación es un comentario que tiene como variable objetivo (target) la probabilidad de ser un comentario tóxico. El objetivo es predecir la toxicidad de cada comentario. Para más detalles pueden visitar el siguiente enlace: [datos](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6101457</td>\n",
       "      <td>What are you talking about? What group do Pete...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5342103</td>\n",
       "      <td>NO!, Let him, we need a Conservative government.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>743361</td>\n",
       "      <td>Perhaps he took the \"power out of the Cardinal...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>551008</td>\n",
       "      <td>As always, yours is dripping with sarcasm, whi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>865998</td>\n",
       "      <td>The dirty little secret is that the price rang...</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                       comment_text  target\n",
       "0  6101457  What are you talking about? What group do Pete...     0.0\n",
       "1  5342103   NO!, Let him, we need a Conservative government.     0.0\n",
       "2   743361  Perhaps he took the \"power out of the Cardinal...     0.2\n",
       "3   551008  As always, yours is dripping with sarcasm, whi...     0.0\n",
       "4   865998  The dirty little secret is that the price rang...     0.3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga de datos de archivos .csv\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/Toxicity.zip')\n",
    "df = df[['id','comment_text', 'target']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Impresión histograma de variable de interés (y)\n",
    "df.target.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    541462.000000\n",
       "mean          0.102991\n",
       "std           0.196979\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.166667\n",
       "max           1.000000\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separación de variable de interés (y)\n",
    "y = df.target\n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X), solo se considera el texto de la noticia\n",
    "X = df.comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         What are you talking about? What group do Pete...\n",
       "1          NO!, Let him, we need a Conservative government.\n",
       "2         Perhaps he took the \"power out of the Cardinal...\n",
       "3         As always, yours is dripping with sarcasm, whi...\n",
       "4         The dirty little secret is that the price rang...\n",
       "                                ...                        \n",
       "541457    You wrote: \"Both parties campaigned explicitly...\n",
       "541458    Nowadays. there sure seem to be a lot of credi...\n",
       "541459    We are lucky wealth filters down to the poor i...\n",
       "541460    You are half right. Both nature and humans can...\n",
       "541461    I don't know how you went from yelling at a fo...\n",
       "Name: comment_text, Length: 541462, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de datos en set de entrenamiento y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 1 - Tokenización con CountVectorizer\n",
    "\n",
    "En la celda 1 creen y entrenen el modelo de regresión de su preferencia, para que prediga la probabilidad de que un comentario sea tóxico, usando los set de entrenamiento y test definidos anteriormente. Usen la función **CountVectorizer** para preprocesar los comentarios y presenten el desempeño del modelo con la métrica del MSE.\n",
    "\n",
    "Recuerden que el preprocesamiento que se haga sobre los datos de entrenamiento  (*.fit_transform()*) deben ser aplicado al set de test (*.transform()*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=True, token_pattern=r'\\b\\w+\\b', stop_words='english')\n",
    "train_vectors = vectorizer.fit_transform(X_train)\n",
    "test_vectors = vectorizer.transform(X_test)\n",
    "\n",
    "svr = SVR(kernel='linear')\n",
    "svr.fit(train_vectors, y_train)\n",
    "predictions = svr.predict(test_vectors)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 2 - Tokenización con CountVectorizer y trigramas\n",
    "\n",
    "En la celda 2 creen y entrenen el mismo modelo de regresión del punto anterior (es decir si usaron un RandomForestRegresor usen nuevamente ese regresor), para que prediga la probabilidad de que un comentario sea tóxico, usando los set de entrenamiento y test definidos anteriormente. Usen la función CountVectorizer **considerando trigramas** para preprocesar los comentarios y presenten el desempeño del modelo con la métrica del MSE.\n",
    "\n",
    "Recuerden que el preprocesamiento que se haga sobre los datos de entrenamiento  (*.fit_transform()*) deben ser aplicado al set de test (*.transform()*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 3 - TfidfVectorizer\n",
    "\n",
    "Investigen sobre la función TfidfVectorizer. En la celda de texto 3, expliquen en qué consiste esta técnica de tokenización (describanla y expliquen su funcionamiento) y cúales son las ventajas o deventajas de su uso al compararlo con la función CountVectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función TfidfVectorizer genera una matriz de de terminos-pesos, es decir, que de cada termino encontrado por dicha libreria en el texto representa una palabra y un peso. Este peso representa la importancia relativa de esa palabra o termino en la base de datos (textos) en comparación con el texto completo o total de registros de texto. \n",
    "\n",
    "Dicha librería contiene la técnica TF-IDF (Term Frequency - Inverse Data Frequency), la cual se basa en dos medidas: la Frecuencia de Término/palabra (TF) y la Inversa de Frecuencia de Documento (IDF). La Frecuencia de Término/palabra es una medida de la frecuencia con la que un término específico aparece en un texto. A continuación se muestra la formula para realizar el calculo: \n",
    "\n",
    "> $tf_{ij} = \\frac{n_{ij}}{\\sum_{k}n_{ij}}$\n",
    "\n",
    "donde i es el termino y j el texto(entiendase como un registro o texto capturado). Entonces seria como el número de veces que aparece el término \"i\" en el texto \"j\") / (Número total de términos en el texto \"j\").\n",
    "\n",
    "La Inversa de Frecuencia de Documento es una medida de la rareza del término en todo el conjunto. La formula seria la siguiente:\n",
    "\n",
    "> $idf(w) = log(\\frac{N}{df_{t}})$\n",
    "\n",
    "En esta fórmula, el numerador es el número total de textos en la base de datos, mientras que el denominador cuenta el número de textos que contienen el término \"t\" en el total de la abse de datos. Dividiendo el numerador por el denominador, obtenemos la proporción de textos que no contienen el término \"t\" en relación al número total de textos. Luego, tomamos el logaritmo natural de esta proporción para obtener un valor positivo que aumenta a medida que disminuye el número de textos que contienen el término \"t\".\n",
    "\n",
    "Ahora para calcular el TF-IDF basta con multiplicar TF y IDF. La formula seria la siguiente:\n",
    "\n",
    "> $w_{ij} = tf_{ij}  * log(\\frac{N}{df_{i}})$\n",
    "\n",
    "Para entender como funciona se plantea el siguiente ejemplo práctico:\n",
    "\n",
    "Supongamos que tenemos un conjunto de cuatro textos (D1, D2, D3, D4) y queremos calcular el valor de TF-IDF para el término \"datos\" en cada documento. Supongamos que el término \"datos\" aparece de la siguiente manera en cada texto:\n",
    "\n",
    "- D1: \"Los datos son importantes en la toma de decisiones\"\n",
    "- D2: \"La cantidad de información recopilada es abrumadora\"\n",
    "- D3: \"El análisis de datos puede ser complejo\"\n",
    "- D4: \"El aprendizaje automático se basa en los datos\"\n",
    "\n",
    "Para calcular la Frecuencia de Término de \"datos\" en cada texto, contamos el número de veces que aparece \"datos\" en cada texto y lo dividimos por el número total de términos en el texto:\n",
    "\n",
    "- TF(\"datos\", D1) = 1/7 = 0.1429\n",
    "- TF(\"datos\", D2) = 0\n",
    "- TF(\"datos\", D3) = 1/5 = 0.2\n",
    "- TF(\"datos\", D4) = 1/6 = 0.1667\n",
    "\n",
    "Observa que en el texto D2 el término \"datos\" no aparece en absoluto, por lo que su frecuencia de término es cero.\n",
    "\n",
    "Para calcular la Inversa de Frecuencia de Documento de \"datos\" en todo el conjunto de textos, contamos el número de textos que contienen \"datos\" y lo dividimos por el número total de textos. Luego, tomamos el logaritmo natural de este cociente:\n",
    "\n",
    "- IDF(\"datos\", {D1, D2, D3, D4}) = log(4/3) = **0.2877**\n",
    "\n",
    "En este caso, el valor de IDF es distinto de cero porque el término \"datos\" no aparece en uno de los textos. El valor de IDF es mayor que cero pero no demasiado alto, lo que sugiere que el término \"datos\" es relativamente común en el conjunto de textos.\n",
    "\n",
    "Finalmente, para calcular el valor de TF-IDF de \"datos\" en cada documento, multiplicamos el valor de TF por el valor de IDF:\n",
    "\n",
    "- TF-IDF(\"datos\", D1) = 0.1429 * 0.2877 = 0.0411\n",
    "- TF-IDF(\"datos\", D2) = 0 * 0.2877 = 0\n",
    "- TF-IDF(\"datos\", D3) = 0.2 * 0.2877 = 0.0575\n",
    "- TF-IDF(\"datos\", D4) = 0.1667 * 0.2877 = 0.048\n",
    "\n",
    "Se observa que el valor de TF-IDF para \"datos\" en cada texto es distinto de cero, excepto en D2, donde no aparece el término \"datos\". Además, el valor de TF-IDF es más alto en los textos donde el término \"datos\" es más relevante para la comprensión del texto (por ejemplo, D3, donde se habla del \"análisis de datos\"), y más bajo en los textos donde el término \"datos\" es menos relevante (por ejemplo, D1, donde se habla de que \"los datos son importantes en la toma de decisiones\", pero no se profundiza demasiado en el tema)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ventajas y desventajas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ventaja de TfidfVectorizer sobre CountVectorizer es que TfidfVectorizer considera tanto la frecuencia de un término en un documento como la frecuencia de aparición del término en todo el conjunto de textos, mientras que CountVectorizer solo considera la frecuencia de aparición del término en el texto. Por lo tanto, TfidfVectorizer puede dar una mayor importancia a los términos que son raros en todo el conjunto pero frecuentes en un texto en particular, lo que puede ser útil para identificar palabras clave en un conjunto de textos.\n",
    "\n",
    "Además, TfidfVectorizer también puede aplicar técnicas de preprocesamiento adicionales, como la eliminación de palabras comunes (stop words), la reducción de palabras a su forma básica (stemming) y la corrección de errores tipográficos.\n",
    "\n",
    "Sin embargo, una desventaja de TfidfVectorizer es que puede ser más lento que CountVectorizer para conjuntos de datos grandes debido a que requiere un cálculo adicional, IDF. También puede ser menos útil en situaciones en las que la frecuencia de un término es más importante que su importancia relativa en todo el conjunto de textos, como en la identificación de nombres de personas o lugares en un texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                       | TfidfVectorizer             | CountVectorizer             |\n",
    "|-----------------------|------------------------------|------------------------------|\n",
    "| Ventajas              | - Da más peso a términos raros | - Útil para análisis simples |\n",
    "|                       |   que pueden ser más         |   de frecuencia de términos  |\n",
    "|                       |   relevantes                  |                              |\n",
    "|                       | - Menos sensible a palabras   | - Sensible a palabras comunes |\n",
    "|                       |   comunes que no aportan      |   que pueden ser ruido       |\n",
    "|                       |   mucha información           | - Es más rápido y simple     |\n",
    "|                       | - Útil para tareas de         | - Es adecuado para tareas de  |\n",
    "|                       |   clasificación y recuperación|   clasificación y recuperación|\n",
    "| Desventajas           | - No es bueno para tareas de  | - Da igual importancia a     |\n",
    "|                       |   análisis simples de         |   palabras comunes y         |\n",
    "|                       |   frecuencia de términos      |   palabras raras             |\n",
    "|                       | - Puede no ser efectivo si    | - No da más peso a palabras  |\n",
    "|                       |   los términos más comunes    |   más raras o relevantes     |\n",
    "|                       |   son importantes             |                              |\n",
    "|                       | - Es más lento y computacional| - No toma en cuenta la       |\n",
    "|                       |   intensivo que CountVectorizer|   relevancia de los términos |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 4 - Tokenización con TfidfVectorizer\n",
    "\n",
    "En la celda 4 creen y entrenen el mismo modelo de regresión del primer punto, para que prediga la probabilidad de que un comentario sea tóxico, usando los set de entrenamiento y test definidos anteriormente. Procesen los comentarios con la función **TfidfVectorizer** y presenten el desempeño del modelo con la métrica del MSE.\n",
    "\n",
    "Recuerden que el preprocesamiento que se haga sobre los datos de entrenamiento  (*.fit_transform()*) deben ser aplicado al set de test (*.transform()*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 5 - Comparación y análisis de resultados\n",
    "\n",
    "En la celda 5 comparen los resultados obtenidos de los diferentes modelos y comenten cómo el preprocesamiento de texto afecta el desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "name": "_merged"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
